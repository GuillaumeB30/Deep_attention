{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7fcd268-afaa-4537-9a25-b31015ac3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28d6ac-6587-4372-a7e6-30ccc193aa29",
   "metadata": {},
   "source": [
    "# Création de la classe Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ca8946-14c1-412b-8ceb-bbcc9b7891bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nans(tensor, tensor_name):\n",
    "    if torch.isnan(tensor).any():\n",
    "        print(f\"NaN detected in {tensor_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4c4f7-aeae-4eb8-9e6a-425adc80d048",
   "metadata": {},
   "source": [
    "Création des différentes couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b435002-af4e-4743-8939-31101cb2422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38f8d9a1-8aec-4970-9a73-141c74d8d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionel : Coder notre propre couche multi-attention head (pour ne pas utiliser celle fournit par torch.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0636a980-6485-4023-b485-732845a49f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(x):\n",
    "    len = x.size(0)\n",
    "    mask = torch.triu(torch.ones(len,len), diagonal = 1) * (-1e9) # Matrice triangulaire supérieur de valeur -inf\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f89e55d-5a9d-4186-98c1-3f4d042fc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, max_length, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_length, d_model)\n",
    "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b1a857c-a787-4f5b-8408-093e8a636158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_heads, d_ff):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.attention = torch.nn.MultiheadAttention(d_model, n_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForwardNetwork(d_model, d_ff)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_output, wei = self.attention(x, x, x)\n",
    "        x = self.norm1(x + attention_output)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm2(x + ffn_output)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2df9652d-bc17-4923-a110-72fb57893c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_heads, d_ff):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.attention1 = torch.nn.MultiheadAttention(d_model, n_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.attention2 = torch.nn.MultiheadAttention(d_model, n_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForwardNetwork(d_model, d_ff)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_output, mask):\n",
    "        attention_output1, wei = self.attention1(x, x, x,attn_mask = mask)\n",
    "        x = self.norm1(x + attention_output1) \n",
    "        attention_output2, wei = self.attention2(x, enc_output, enc_output)\n",
    "        x = self.norm2(x + attention_output2)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm3(x + ffn_output)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f440a5e-05d8-48ad-97c3-8b42eeaa1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, target_size, max_length, d_model, num_heads, d_ff, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.enc_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.dec_embedding = nn.Embedding(target_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(max_length, d_model)\n",
    "        \n",
    "        self.encoder_layers = [Encoder(d_model, num_heads,d_ff) for i in range(n_layers)]\n",
    "        self.decoder_layers = [Decoder(d_model, num_heads, d_ff) for i in range(n_layers)]\n",
    "\n",
    "        self.linear = nn.Linear(d_model, target_size)\n",
    "\n",
    "    def check_for_nans(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if torch.isnan(param).any():\n",
    "                print(f\"NaN detected in parameter: {name}\")\n",
    "\n",
    "    def forward(self,inp,out):\n",
    "\n",
    "        check_for_nans(inp,\"inp\")\n",
    "        check_for_nans(out, \"out\")\n",
    "        \n",
    "        mask = create_mask(out)\n",
    "\n",
    "        check_for_nans(mask, \"mask\")\n",
    "        \n",
    "        out_embedded = self.positional_encoding(self.dec_embedding(out))\n",
    "        inp_embedded = self.positional_encoding(self.enc_embedding(inp))\n",
    "\n",
    "        check_for_nans(out_embedded, \"out_embedded\")\n",
    "        check_for_nans(inp_embedded, \"inp_embedded\")\n",
    "        \n",
    "        enc_output = inp_embedded\n",
    "        for encoder in self.encoder_layers:\n",
    "            enc_output = encoder(enc_output)\n",
    "\n",
    "        check_for_nans(enc_output, \"enc_output\")\n",
    "        \n",
    "        dec_output = out_embedded\n",
    "        for decoder in self.decoder_layers:\n",
    "            dec_output = decoder(dec_output, enc_output, mask)\n",
    "\n",
    "        check_for_nans(dec_output, \"dec_output\")\n",
    "        \n",
    "        output = self.linear(dec_output)\n",
    "\n",
    "        check_for_nans(output, \"output\")\n",
    "        return output   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bca86b-2ff1-4662-b9c4-8eb454e41c00",
   "metadata": {},
   "source": [
    "# Mise en forme des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "de786ef9-1eff-42d1-8194-4089c3bfb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "18c64f66-c4ab-4f7b-b0c6-dab3315ece99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "with open(\"eng_-french.csv\",encoding = \"utf-8\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        y.append(row[0])\n",
    "        x.append(row[-1])\n",
    "    x.pop(0)\n",
    "    y.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "967b8ebd-00d2-416e-9912-8aa2e7a9bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_red = x[:10000]\n",
    "y_red = y[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a43238cc-b560-43c9-8b7e-54c966e14c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9f7bdd50-a7f2-46e1-b458-61c837afead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_red, y_red, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "91a6d0a8-833c-4907-9df4-3829664415b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [word_tokenize(word) for word in x_train]\n",
    "y_train = [word_tokenize(word) for word in y_train]\n",
    "x_test = [word_tokenize(word) for word in x_test]\n",
    "y_test = [word_tokenize(word) for word in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f8082190-7af8-422d-b9e3-e9555a376944",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    for j in range(len(x_train[i])-1,-1,-1):\n",
    "        if x_train[i][j] in punctuation:\n",
    "            x_train[i].pop(j)\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    for j in range(len(y_train[i])-1,-1,-1):\n",
    "        if y_train[i][j] in punctuation:\n",
    "            y_train[i].pop(j)\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    for j in range(len(x_test[i])-1,-1,-1):\n",
    "        if x_test[i][j] in punctuation:\n",
    "            x_test[i].pop(j)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    for j in range(len(y_test[i])-1,-1,-1):\n",
    "        if y_test[i][j] in punctuation:\n",
    "            y_test[i].pop(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "742b3078-e24b-4aa9-92e6-9151cf6b2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] = [stemmer.stem(word) for word in y_train[i]]\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i] = [stemmer.stem(word) for word in x_train[i]]\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    y_test[i] = [stemmer.stem(word) for word in y_test[i]]\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    x_test[i] = [stemmer.stem(word) for word in x_test[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ab48ef8b-7698-40b7-872e-bbea32e9a233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3391\n",
      "1587\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "target_vocab = []\n",
    "for sentence in x_train:\n",
    "    for word in sentence:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "\n",
    "for sentence in y_train:\n",
    "    for word in sentence:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)\n",
    "\n",
    "print(len(vocab))\n",
    "print(len(target_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a6127f19-7f99-4389-88a9-ab71b2849165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8e53e39d-1617-4ea6-a6cf-ff16f08bd011",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "for sentence in x_train:\n",
    "    for word in sentence:\n",
    "        cnt[word] += 1\n",
    "\n",
    "li = cnt.most_common(len(vocab))\n",
    "vocab = {}\n",
    "for i in range(len(li)):\n",
    "    word, n = li[i]\n",
    "    vocab[word] = i + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "35ff652d-0583-48bc-8aca-9e6d5efc416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "for sentence in y_train:\n",
    "    for word in sentence:\n",
    "        cnt[word] += 1\n",
    "\n",
    "li = cnt.most_common(len(target_vocab))\n",
    "target_vocab = {}\n",
    "for i in range(len(li)):\n",
    "    word, n = li[i]\n",
    "    target_vocab[word] = i + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "56b67544-1049-4bc2-999e-6eb3c2da6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in x_train:\n",
    "    for i in range(len(sentence) - 1, -1, -1):\n",
    "        if sentence[i] not in vocab:\n",
    "            sentence.pop(i)\n",
    "        else:\n",
    "            sentence[i] = vocab[sentence[i]]\n",
    "\n",
    "for sentence in x_test:\n",
    "    for i in range(len(sentence) - 1, -1, -1):\n",
    "        if sentence[i] not in vocab:\n",
    "            sentence.pop(i)\n",
    "        else:\n",
    "            sentence[i] = vocab[sentence[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "79491abf-1b39-493a-a1bd-1708b2665a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in y_train:\n",
    "    for i in range(len(sentence) - 1, -1, -1):\n",
    "        if sentence[i] not in target_vocab:\n",
    "            sentence.pop(i)\n",
    "        else:\n",
    "            sentence[i] = target_vocab[sentence[i]]\n",
    "\n",
    "for sentence in y_test:\n",
    "    for i in range(len(sentence) - 1, -1, -1):\n",
    "        if sentence[i] not in target_vocab:\n",
    "            sentence.pop(i)\n",
    "        else:\n",
    "            sentence[i] = target_vocab[sentence[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d4dd3817-5a91-4f9b-9387-5c099ac2f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector(li, max_length):\n",
    "    if len(li) > max_length:\n",
    "        return [1] + li[:max_length] + [2]\n",
    "    else:\n",
    "        return [1] + li + [3 for i in range(max_length - len(li))] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5ff529f5-ec3e-4dc8-bf7a-110f56df6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = make_vector(x_train[i], 40)\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] = make_vector(y_train[i], 40)\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    x_test[i] = make_vector(x_test[i], 40)\n",
    "for i in range(len(y_test)):\n",
    "    y_test[i] = make_vector(y_test[i], 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "87e63a0a-16b2-4972-8782-ae8582734feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import IntTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9bd0dc57-d004-4a4c-acc3-481d671dd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des Dataloader\n",
    "trainset = TensorDataset(IntTensor(x_train), IntTensor(y_train))\n",
    "train_dataloader = DataLoader(trainset, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "testset = TensorDataset(IntTensor(x_test), IntTensor(y_test))\n",
    "test_dataloader = DataLoader(testset, batch_size=1, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59756bcd-fe3f-4687-a17b-2324a95cd264",
   "metadata": {},
   "source": [
    "# Entrainement du transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2aa7785f-f85e-4581-8070-50327963b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b4851d60-806b-4f18-b1d4-46dc0769638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = Transformer(len(vocab) + 4,len(target_vocab) + 4, 42, 512, 8, 1024, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "1ce976a0-68a6-40a7-a6fe-5d2709fa2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(tf1.parameters(),lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a7e5bc81-6d05-47a8-8d60-47cbaa43ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        batch_size = len(y)\n",
    "        pred = model(X, y)\n",
    "        pred = pred.view(-1, pred.size(-1))  # [batch_size * seq_len, num_classes]\n",
    "        y = y.view(-1)  # [batch_size * seq_len]\n",
    "        y = y.long()\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "7bb21a0f-f080-48b7-95d9-01c027f6517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 8.246761  [   32/ 8000]\n",
      "loss: 7.561241  [ 3232/ 8000]\n",
      "loss: 6.849017  [ 6432/ 8000]\n",
      "loss: 6.491234  [   32/ 8000]\n",
      "loss: 5.809368  [ 3232/ 8000]\n",
      "loss: 5.106065  [ 6432/ 8000]\n",
      "loss: 4.766796  [   32/ 8000]\n",
      "loss: 4.098043  [ 3232/ 8000]\n",
      "loss: 3.438899  [ 6432/ 8000]\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 3\n",
    "for i in range(nb_epoch):\n",
    "    train_loop(train_dataloader, tf1,loss_fn, adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e911d-fff1-465b-99e5-ba29ca44c14a",
   "metadata": {},
   "source": [
    "# Prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "3b1ee318-72e1-42c8-bd8c-315d2f0379b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src_tensor, max_len=10, start_token=1, end_token=2):\n",
    "    output = []\n",
    "    # Initial decoder token (start token for each batch)\n",
    "    batch_size = src_tensor.shape[0]  # Get batch size from the source tensor (second dimension)\n",
    "    dec_input = torch.full((1, batch_size), start_token, dtype=torch.long)  # Shape: (1, batch_size)\n",
    "\n",
    "    # Transpose the src_tensor to match (seq_len, batch_size, embedding_size)\n",
    "    src_tensor = src_tensor.transpose(0, 1)  # Transpose to (batch_size, seq_len, embedding_size)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        # Get decoder output from the model (shape: batch_size, seq_len, vocab_size)\n",
    "        dec_output = model(src_tensor, dec_input)  # Assuming model works with the new input shape\n",
    "\n",
    "        # Select the most likely token (argmax over vocab_size)\n",
    "        next_token = dec_output[-1, :, :].argmax(dim=-1)  # Shape: (batch_size,)\n",
    "        \n",
    "        # Append the next token for each sequence in the batch\n",
    "        output.extend(next_token.tolist())  # This will append all tokens for the current batch\n",
    "        \n",
    "        # Convert next_token to shape (batch_size, 1) for concatenation\n",
    "        next_token = next_token.unsqueeze(0)  # Shape: (1, batch_size)\n",
    "        next_token = next_token.transpose(0,1)\n",
    "        \n",
    "        # Concatenate next_token along the sequence dimension (dim=1)\n",
    "        dec_input = torch.cat([dec_input, next_token], dim=0)  # Shape: (seq_len+1, batch_size)\n",
    "\n",
    "\n",
    "        # Stop if all sequences generate the end token\n",
    "        if (next_token == end_token).all():  # If all sequences generate end_token\n",
    "            break\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "336896ff-673d-4029-8877-7005fd9c00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(x):\n",
    "    for i in range(len(x)):\n",
    "        if x[i] <= 3:\n",
    "            x[i] = \"\"\n",
    "        else:    \n",
    "            for keys in target_vocab.keys():\n",
    "                if x[i] == target_vocab[keys]:\n",
    "                    x[i] = keys\n",
    "    sentence = \"\"\n",
    "    for i in range(len(x)):\n",
    "        sentence += x[i] + \" \"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "33962b3b-f4d2-48f5-bc9b-171ddf4cafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a940c828-b351-4b55-a570-0563316fb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    total_bleu = 0\n",
    "    for  batch, (X, y) in enumerate(dataloader): \n",
    "        predicted_tokens = greedy_decode(model, X)\n",
    "        predicted_translation = decode(predicted_tokens)\n",
    "        \n",
    "        target = decode(y.tolist()[0])\n",
    "        bleu_score = sentence_bleu(target,predicted_translation )\n",
    "        total_bleu += bleu_score\n",
    "\n",
    "    avg_bleu = total_bleu / len(dataloader)\n",
    "    print(f\"Average BLEU Score: {avg_bleu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ddf990b0-fe76-4fcc-a7c8-c84e60f4bd55",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[258], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evaluate_model(tf1, test_dataloader)\n",
      "Cell \u001b[1;32mIn[244], line 5\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m      3\u001b[0m total_bleu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m  batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader): \n\u001b[1;32m----> 5\u001b[0m     predicted_tokens \u001b[38;5;241m=\u001b[39m greedy_decode(model, X)\n\u001b[0;32m      6\u001b[0m     predicted_translation \u001b[38;5;241m=\u001b[39m decode(predicted_tokens)\n\u001b[0;32m      8\u001b[0m     target \u001b[38;5;241m=\u001b[39m decode(y\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[238], line 12\u001b[0m, in \u001b[0;36mgreedy_decode\u001b[1;34m(model, src_tensor, max_len, start_token, end_token)\u001b[0m\n\u001b[0;32m      8\u001b[0m src_tensor \u001b[38;5;241m=\u001b[39m src_tensor\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Transpose to (batch_size, seq_len, embedding_size)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Get decoder output from the model (shape: batch_size, seq_len, vocab_size)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     dec_output \u001b[38;5;241m=\u001b[39m model(src_tensor, dec_input)  \u001b[38;5;66;03m# Assuming model works with the new input shape\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Select the most likely token (argmax over vocab_size)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m dec_output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :, :]\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch_size,)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[88], line 37\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, inp, out)\u001b[0m\n\u001b[0;32m     35\u001b[0m enc_output \u001b[38;5;241m=\u001b[39m inp_embedded\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layers:\n\u001b[1;32m---> 37\u001b[0m     enc_output \u001b[38;5;241m=\u001b[39m encoder(enc_output)\n\u001b[0;32m     39\u001b[0m check_for_nans(enc_output, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menc_output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m dec_output \u001b[38;5;241m=\u001b[39m out_embedded\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[84], line 14\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     13\u001b[0m     attention_output, wei \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(x, x, x)\n\u001b[1;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m attention_output)\n\u001b[0;32m     15\u001b[0m     ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(x)\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m ffn_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_model(tf1, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ad6867c4-1511-4447-ab7c-be45417e6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(x,model = tf1):\n",
    "    x = word_tokenize(x)\n",
    "    for i in range(len(x) - 1, -1, -1):\n",
    "        if x[i] in punctuation:\n",
    "            x.pop(i)\n",
    "    x = [stemmer.stem(word) for word in x]\n",
    "    for i in range(len(x) - 1, -1, -1):\n",
    "        if x[i] not in vocab:\n",
    "            x.pop(i)\n",
    "        else:\n",
    "            x[i] = vocab[x[i]]\n",
    "    x = make_vector(x, 40)\n",
    "    x = [x]\n",
    "    xset = TensorDataset(IntTensor(x), IntTensor(x))\n",
    "    x_dataloader = DataLoader(xset, batch_size=1, shuffle=True, drop_last=True)\n",
    "    \n",
    "    for  batch, (X, y) in enumerate(x_dataloader):\n",
    "        predicted_tokens = greedy_decode(model, X)\n",
    "        print(predicted_tokens)\n",
    "        print(batch)\n",
    "        x = decode(predicted_tokens)   \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a643db19-e257-42a6-ad5e-9a3ae41f04ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'          '"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Etre ou ne pas etre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adee14f-3a26-4b69-abcb-85a266893262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
