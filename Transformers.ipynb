{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fcd268-afaa-4537-9a25-b31015ac3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28d6ac-6587-4372-a7e6-30ccc193aa29",
   "metadata": {},
   "source": [
    "# Création de la classe Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4c4f7-aeae-4eb8-9e6a-425adc80d048",
   "metadata": {},
   "source": [
    "Création des différentes couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0b435002-af4e-4743-8939-31101cb2422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "38f8d9a1-8aec-4970-9a73-141c74d8d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionel : Coder notre propre couche multi-attention head (pour ne pas utiliser celle fournit par torch.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "0636a980-6485-4023-b485-732845a49f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(x):\n",
    "    len = x.size(0)\n",
    "    mask = torch.triu(torch.ones(len,len), diagonal = 1) * (-1) * float(\"inf\") # Matrice triangulaire supérieur de valeur -inf\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7f89e55d-5a9d-4186-98c1-3f4d042fc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, max_length, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_length, d_model)\n",
    "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1b1a857c-a787-4f5b-8408-093e8a636158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_heads, d_ff):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.attention = torch.nn.MultiheadAttention(d_model, n_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForwardNetwork(d_model, d_ff)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_output, wei = self.attention(x, x, x)\n",
    "        x = self.norm1(x + attention_output)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm2(x + ffn_output)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "2df9652d-bc17-4923-a110-72fb57893c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_heads, d_ff):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.attention1 = torch.nn.MultiheadAttention(d_model, n_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.attention2 = torch.nn.MultiheadAttention(d_model, n_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForwardNetwork(d_model, d_ff)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_output, mask):\n",
    "        attention_output1, wei = self.attention1(x, x, x,attn_mask = mask)\n",
    "        x = self.norm1(x + attention_output1)\n",
    "        attention_output2, wei = self.attention2(x, enc_output, enc_output)\n",
    "        x = self.norm2(x + attention_output2)\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm3(x + ffn_output)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "2f440a5e-05d8-48ad-97c3-8b42eeaa1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, target_size, max_length, d_model, num_heads, d_ff, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.enc_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.dec_embedding = nn.Embedding(target_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(max_length, d_model)\n",
    "        \n",
    "        self.encoder_layers = [Encoder(d_model, num_heads,d_ff) for i in range(n_layers)]\n",
    "        self.decoder_layers = [Decoder(d_model, num_heads, d_ff) for i in range(n_layers)]\n",
    "\n",
    "        self.linear = nn.Linear(d_model, target_size)\n",
    "\n",
    "    def forward(self,inp,out):\n",
    "        mask = create_mask(out)\n",
    "        out_embedded = self.positional_encoding(self.dec_embedding(out))\n",
    "        inp_embedded = self.positional_encoding(self.enc_embedding(inp))\n",
    "\n",
    "        enc_output = inp_embedded\n",
    "        for encoder in self.encoder_layers:\n",
    "            enc_output = encoder(enc_output)\n",
    "\n",
    "        dec_output = out_embedded\n",
    "        for decoder in self.decoder_layers:\n",
    "            dec_output = decoder(dec_output, enc_output, mask)\n",
    "\n",
    "        output = self.linear(dec_output)\n",
    "\n",
    "        return output   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bca86b-2ff1-4662-b9c4-8eb454e41c00",
   "metadata": {},
   "source": [
    "# Mise en forme des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "de786ef9-1eff-42d1-8194-4089c3bfb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "18c64f66-c4ab-4f7b-b0c6-dab3315ece99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "with open(\"eng_-french.csv\",encoding = \"utf-8\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        y.append(row[0])\n",
    "        x.append(row[-1])\n",
    "    x.pop(0)\n",
    "    y.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "967b8ebd-00d2-416e-9912-8aa2e7a9bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_red = x[:10000]\n",
    "y_red = y[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "91a6d0a8-833c-4907-9df4-3829664415b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [word_tokenize(word) for word in x_red]\n",
    "y_train = [word_tokenize(word) for word in y_red]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f8082190-7af8-422d-b9e3-e9555a376944",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    for j in range(len(x_train[i])-1,-1,-1):\n",
    "        if x_train[i][j] in punctuation:\n",
    "            x_train[i].pop(j)\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    for j in range(len(y_train[i])-1,-1,-1):\n",
    "        if y_train[i][j] in punctuation:\n",
    "            y_train[i].pop(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "742b3078-e24b-4aa9-92e6-9151cf6b2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] = [stemmer.stem(word) for word in y_train[i]]\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i] = [stemmer.stem(word) for word in x_train[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ab48ef8b-7698-40b7-872e-bbea32e9a233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3796\n",
      "1719\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "target_vocab = []\n",
    "for sentence in x_train:\n",
    "    for word in sentence:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "\n",
    "for sentence in y_train:\n",
    "    for word in sentence:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)\n",
    "\n",
    "print(len(vocab))\n",
    "print(len(target_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a6127f19-7f99-4389-88a9-ab71b2849165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "8e53e39d-1617-4ea6-a6cf-ff16f08bd011",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "for sentence in x_train:\n",
    "    for word in sentence:\n",
    "        cnt[word] += 1\n",
    "\n",
    "li = cnt.most_common(len(vocab))\n",
    "vocab = {}\n",
    "for i in range(len(li)):\n",
    "    word, n = li[i]\n",
    "    vocab[word] = i + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "35ff652d-0583-48bc-8aca-9e6d5efc416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "for sentence in y_train:\n",
    "    for word in sentence:\n",
    "        cnt[word] += 1\n",
    "\n",
    "li = cnt.most_common(len(target_vocab))\n",
    "target_vocab = {}\n",
    "for i in range(len(li)):\n",
    "    word, n = li[i]\n",
    "    target_vocab[word] = i + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "56b67544-1049-4bc2-999e-6eb3c2da6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in x_train:\n",
    "    for i in range(len(sentence) - 1, -1, -1):\n",
    "        if sentence[i] not in vocab:\n",
    "            sentence.pop(i)\n",
    "        else:\n",
    "            sentence[i] = vocab[sentence[i]]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "79491abf-1b39-493a-a1bd-1708b2665a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in y_train:\n",
    "    for i in range(len(sentence) - 1, -1, -1):\n",
    "        if sentence[i] not in target_vocab:\n",
    "            sentence.pop(i)\n",
    "        else:\n",
    "            sentence[i] = target_vocab[sentence[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "d4dd3817-5a91-4f9b-9387-5c099ac2f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector(li, max_length):\n",
    "    if len(li) > max_length:\n",
    "        return [1] + li[:max_length] + [2]\n",
    "    else:\n",
    "        return [1] + li + [0 for i in range(max_length - len(li))] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "5ff529f5-ec3e-4dc8-bf7a-110f56df6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = make_vector(x_train[i], 40)\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] = make_vector(y_train[i], 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "87e63a0a-16b2-4972-8782-ae8582734feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import IntTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "9bd0dc57-d004-4a4c-acc3-481d671dd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des Dataloader\n",
    "trainset = TensorDataset(IntTensor(x_train), IntTensor(y_train))\n",
    "train_dataloader = DataLoader(trainset, batch_size=16, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59756bcd-fe3f-4687-a17b-2324a95cd264",
   "metadata": {},
   "source": [
    "# Entrainement du transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "2aa7785f-f85e-4581-8070-50327963b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "b4851d60-806b-4f18-b1d4-46dc0769638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = Transformer(len(vocab) + 3,len(target_vocab) + 3, 42, 512, 8, 1024, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "1ce976a0-68a6-40a7-a6fe-5d2709fa2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(tf1.parameters(),lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "a7e5bc81-6d05-47a8-8d60-47cbaa43ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        batch_size = len(y)\n",
    "        pred = model(X, y)\n",
    "        pred = pred.view(-1, pred.size(-1))  # [batch_size * seq_len, num_classes]\n",
    "        y = y.view(-1)  # [batch_size * seq_len]\n",
    "        y = y.long()\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print(torch.min(y), torch.max(y))\n",
    "            print(torch.min(pred), torch.max(pred))\n",
    "            print(torch.isnan(X).any())\n",
    "            for name, param in model.named_parameters():\n",
    "                if torch.isnan(param).any():\n",
    "                    print(f\"NaN detected in parameter: {name}\")\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "7bb21a0f-f080-48b7-95d9-01c027f6517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor(925)\n",
      "tensor(nan, grad_fn=<MinBackward1>) tensor(nan, grad_fn=<MaxBackward1>)\n",
      "tensor(False)\n",
      "NaN detected in parameter: enc_embedding.weight\n",
      "NaN detected in parameter: dec_embedding.weight\n",
      "NaN detected in parameter: linear.weight\n",
      "NaN detected in parameter: linear.bias\n",
      "loss:     nan  [   16/10000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[416], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m nb_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_epoch):\n\u001b[1;32m----> 3\u001b[0m     train_loop(train_dataloader, tf1,loss_fn, adam)\n",
      "Cell \u001b[1;32mIn[414], line 16\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 3\n",
    "for i in range(nb_epoch):\n",
    "    train_loop(train_dataloader, tf1,loss_fn, adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8363c-a286-4233-856a-42999e616cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
